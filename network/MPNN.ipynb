{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, OptPairTensor, Adj, Size\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ROOT import TLorentzVector\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy( np.load('/data/github/data/diHiggs_kin_train_data.npy').astype(np.float32))\n",
    "data2 = torch.from_numpy( np.load('/data/github/data/diHiggs_kin_test_data.npy').astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_, e2_ = [], []\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        e1_.append(i)\n",
    "        e2_.append(j)\n",
    "        \n",
    "def graph_trans(d, y=1, e1=e1_, e2=e2_):\n",
    "    b1, b2, l1, l2, nu1, nu2 = TLorentzVector(), TLorentzVector(), TLorentzVector(), TLorentzVector(), TLorentzVector(), TLorentzVector()\n",
    "    b1.SetPxPyPzE(d[17], d[18], d[19], d[20])\n",
    "    b2.SetPxPyPzE(d[21], d[22], d[23], d[24])\n",
    "    l1.SetPxPyPzE(d[25], d[26], d[27], d[28])\n",
    "    l2.SetPxPyPzE(d[29], d[30], d[31], d[32])\n",
    "    nu1.SetPxPyPzE(d[33], d[34], d[35], d[36])\n",
    "    nu2.SetPxPyPzE(d[37], d[38], d[39], d[40])\n",
    "\n",
    "    x = torch.tensor([[0, 1, 0, b1.Pt()/500., b1.E()/500., b1.M()],\n",
    "                     [0, -1, 0, b2.Pt()/500., b2.E()/500., b2.M()],\n",
    "                     [1, 0, 0, l1.Pt()/200., l1.E()/200., l1.M()],\n",
    "                     [-1, 0, 0, l2.Pt()/200., l2.E()/200., l2.M()],\n",
    "                     [0, 0, 1, nu1.Pt()/50., nu1.E()/50., nu1.M()],\n",
    "                     [0, 0, -1, nu2.Pt()/50., nu2.E()/50., nu2.M()]], dtype=torch.float)\n",
    "\n",
    "    edge_attr = []\n",
    "    e1_, e2_ = [], []\n",
    "    for i in range(6):\n",
    "        edge_attr_i = []\n",
    "        for j in range(6):\n",
    "            e1_.append(i)\n",
    "            e2_.append(j)\n",
    "            edge_attr_i.append([b1, b2, l1, l2, nu1, nu2][i].DeltaR([b1, b2, l1, l2, nu1, nu2][j]))\n",
    "        edge_attr.append(edge_attr_i)\n",
    "\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    GNN_index = torch.tensor([e1, e2], dtype=torch.long)\n",
    "\n",
    "\n",
    "    graph = Data(x=x, y=[y, y, y, y, y, y], GNN_index=GNN_index, edge_attr=edge_attr)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_list = []\n",
    "for idx, d in enumerate(data):\n",
    "    if(idx<=19000):\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "    train_graph_list.append(graph_trans(d, y))\n",
    "\n",
    "test_graph_list = []\n",
    "for idx, d in enumerate(data2):\n",
    "    if(idx<=5000):\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "    test_graph_list.append(graph_trans(d, y))\n",
    "    \n",
    "    \n",
    "train_loader = DataLoader(train_graph_list, \n",
    "                          batch_size=109,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_graph_list, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNConv0(MessagePassing):\n",
    "    def __init__(self, in_channels, hidden1, hidden2, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.mlp0 = Seq(Linear(in_channels, hidden1, bias=True),\n",
    "                               ReLU())\n",
    "        self.mlp1 = Seq(Linear(hidden1+1, hidden2, bias=True),\n",
    "                       ReLU())\n",
    "        self.mlp2 = Seq(Linear(hidden2+hidden1, out_channels, bias=True),\n",
    "                       ReLU())\n",
    "\n",
    "\n",
    "    def forward(self, x, GNN_index, edge_attr): \n",
    "        x = self.mlp0(x)\n",
    "        out = self.propagate(GNN_index, x=x, edge_attr=edge_attr)\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        out = self.mlp2(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr_j):\n",
    "        edge_info = edge_attr_j[:, i]\n",
    "        edge_info = edge_info[:, None]\n",
    "        x_j = torch.cat([x_j, edge_info], dim=1)\n",
    "        x_j = self.mlp1(x_j)\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, hidden, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.mlp1 = Seq(Linear(in_channels+1, hidden, bias=True),\n",
    "                       ReLU())\n",
    "        self.mlp2 = Seq(Linear(hidden+in_channels, out_channels, bias=True),\n",
    "                       ReLU())\n",
    "\n",
    "\n",
    "    def forward(self, x, GNN_index, edge_attr):        \n",
    "        out = self.propagate(GNN_index, x=x, edge_attr=edge_attr)\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        out = self.mlp2(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr_j):\n",
    "        edge_info = edge_attr_j[:, i]\n",
    "        edge_info = edge_info[:, None]\n",
    "        x_j = torch.cat([x_j, edge_info], dim=1)\n",
    "        x_j = self.mlp1(x_j)\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GNNConv0(6, 58, 64, 116)\n",
    "        self.conv2 = GNNConv(116, 4, 30)\n",
    "        self.conv3 = GNNConv(30, 107, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, GNN_index = data.x, data.GNN_index\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, GNN_index, edge_attr)\n",
    "        x = self.conv2(x, GNN_index, edge_attr)\n",
    "        x = self.conv3(x, GNN_index, edge_attr)\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MPNN().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=3.588112521749169e-05,\n",
    "                             betas=(0.9370461057934745, 0.9911704693310439),\n",
    "                             weight_decay=0.010816528466771117,\n",
    "                            )\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.9409084329632221\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    loss_val = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label = torch.tensor(np.concatenate(batch.y)).to(device)\n",
    "        out = model(batch.to(device))\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val.append(loss.item())\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    loss = np.mean(loss_val)\n",
    "    \n",
    "    print(f'\\n Train Epoch: {epoch} \\tLoss: {loss:.6f}')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a57c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    DNN_score1 = open('/data/github/result/MPNN_DNN_score1.TXT', 'a')    \n",
    "    DNN_score2 = open('/data/github/result/MPNN_DNN_score2.TXT', 'a')\n",
    "\n",
    "    model.eval()\n",
    "    loss_val = []\n",
    "    for idx, batch in enumerate(test_loader):\n",
    "        out = model(batch.to(device)) \n",
    "        loss = criterion(out, torch.tensor(np.concatenate(batch.y)).to(device))\n",
    "        \n",
    "        loss_val.append(loss.item())\n",
    "\n",
    "        out = (out.cpu().detach().numpy())[:]\n",
    "        if(idx==0):\n",
    "            test_out = out[:]\n",
    "            test_y = np.array(batch.y)[:]\n",
    "        else:\n",
    "            test_out = np.concatenate((test_out[:], out[:]), axis=0)\n",
    "            test_y = np.concatenate((test_y[:], np.array(batch.y)[:]), axis=0)\n",
    "\n",
    "\n",
    "    for n in range(0,len(test_out)):\n",
    "        DNN_score1.write(str((test_out[:,0:1][n].item())) + ' ' + str((test_out[:,1:2][n].item())))\n",
    "        DNN_score1.write('\\n')\n",
    "        \n",
    "    for n in range(0,len(test_y)):\n",
    "        DNN_score2.write(str((test_y[:,0:1][n].item())) + ' ' + str((test_y[:,1:2][n].item())) + ' ' + str((test_y[:,2:3][n].item())) + ' ' + str((test_y[:,3:4][n].item())) + ' ' + str((test_y[:,4:5][n].item())) + ' ' + str((test_y[:,5:6][n].item())))\n",
    "        DNN_score2.write('\\n')\n",
    "    \n",
    "    loss = np.mean(loss_val)\n",
    "\n",
    "    print(f'\\nTest set: Loss: {loss:.6f}\\n')\n",
    "    print('----------------------------------------------------')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beea3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Like(s, b, u, n):\n",
    "    return math.e**((n*s+b)*math.log(u*s+b)-math.lgamma(n*s+b+1)-(u*s+b))\n",
    "\n",
    "def IndiLikeRatioDis(NS1, NB1):\n",
    "    return math.sqrt(-2*math.log((Like(NS1, NB1, 0.0, 1.0))/(Like(NS1, NB1, 1.0, 1.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_score1 = open('/data/github/result/MPNN_DNN_score1.TXT', 'w')    \n",
    "DNN_score2 = open('/data/github/result/MPNN_DNN_score2.TXT', 'w')\n",
    "\n",
    "Train_Loss = []\n",
    "Test_Loss = []\n",
    "\n",
    "epochs = 1\n",
    "best_sig = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start=time.time()\n",
    "    print('########### Training epoch {} start ###########'.format(epoch))\n",
    "    \n",
    "    train_loss = train(model, train_loader)\n",
    "    test_loss = test(model, test_loader)\n",
    "\n",
    "    Train_Loss.append(train_loss)\n",
    "    Test_Loss.append(test_loss)\n",
    "    \n",
    "    epoch_ = epoch\n",
    "\n",
    "    Results1 = np.loadtxt('/data/github/result/MPNN_DNN_score1.TXT')\n",
    "    Results2 = np.loadtxt('/data/github/result/MPNN_DNN_score2.TXT')\n",
    "\n",
    "    test_out = Results1[151500*(epoch_-1):151500*(epoch_)]\n",
    "    test_y = Results2[25250*(epoch_-1):25250*(epoch_)]\n",
    "    \n",
    "    Results_hh_1=test_out[:,1:2][:25250][:5000]\n",
    "    Results_tt_1=test_out[:,1:2][:25250][5000:5000+19000]\n",
    "    Results_tw_1=test_out[:,1:2][:25250][5000+19000:5000+19000+800]\n",
    "    Results_tth_1=test_out[:,1:2][:25250][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_1=test_out[:,1:2][:25250][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_1=test_out[:,1:2][:25250][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_1=test_out[:,1:2][:25250][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    Results_hh_2=test_out[:,1:2][25250:25250*2][:5000]\n",
    "    Results_tt_2=test_out[:,1:2][25250:25250*2][5000:5000+19000]\n",
    "    Results_tw_2=test_out[:,1:2][25250:25250*2][5000+19000:5000+19000+800]\n",
    "    Results_tth_2=test_out[:,1:2][25250:25250*2][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_2=test_out[:,1:2][25250:25250*2][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_2=test_out[:,1:2][25250:25250*2][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_2=test_out[:,1:2][25250:25250*2][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    Results_hh_3=test_out[:,1:2][25250*2:25250*3][:5000]\n",
    "    Results_tt_3=test_out[:,1:2][25250*2:25250*3][5000:5000+19000]\n",
    "    Results_tw_3=test_out[:,1:2][25250*2:25250*3][5000+19000:5000+19000+800]\n",
    "    Results_tth_3=test_out[:,1:2][25250*2:25250*3][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_3=test_out[:,1:2][25250*2:25250*3][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_3=test_out[:,1:2][25250*2:25250*3][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_3=test_out[:,1:2][25250*2:25250*3][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    Results_hh_4=test_out[:,1:2][25250*3:25250*4][:5000]\n",
    "    Results_tt_4=test_out[:,1:2][25250*3:25250*4][5000:5000+19000]\n",
    "    Results_tw_4=test_out[:,1:2][25250*3:25250*4][5000+19000:5000+19000+800]\n",
    "    Results_tth_4=test_out[:,1:2][25250*3:25250*4][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_4=test_out[:,1:2][25250*3:25250*4][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_4=test_out[:,1:2][25250*3:25250*4][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_4=test_out[:,1:2][25250*3:25250*4][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    Results_hh_5=test_out[:,1:2][25250*4:25250*5][:5000]\n",
    "    Results_tt_5=test_out[:,1:2][25250*4:25250*5][5000:5000+19000]\n",
    "    Results_tw_5=test_out[:,1:2][25250*4:25250*5][5000+19000:5000+19000+800]\n",
    "    Results_tth_5=test_out[:,1:2][25250*4:25250*5][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_5=test_out[:,1:2][25250*4:25250*5][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_5=test_out[:,1:2][25250*4:25250*5][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_5=test_out[:,1:2][25250*4:25250*5][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    Results_hh_6=test_out[:,1:2][25250*5:25250*6][:5000]\n",
    "    Results_tt_6=test_out[:,1:2][25250*5:25250*6][5000:5000+19000]\n",
    "    Results_tw_6=test_out[:,1:2][25250*5:25250*6][5000+19000:5000+19000+800]\n",
    "    Results_tth_6=test_out[:,1:2][25250*5:25250*6][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_6=test_out[:,1:2][25250*5:25250*6][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_6=test_out[:,1:2][25250*5:25250*6][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_6=test_out[:,1:2][25250*5:25250*6][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='Time New Roman')\n",
    "\n",
    "    logs = False\n",
    "\n",
    "    axislabels = [ r'$DNN $']\n",
    "\n",
    "    Yaxislabels = [ r'$DNN $']\n",
    "\n",
    "    Bmax = 1\n",
    "    Bmin = 0\n",
    "    plt.xlim(0, 1)\n",
    "    bins = np.linspace(Bmin, Bmax,  25)\n",
    "    plt.hist(Results_hh_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(Results_hh_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_2, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(Results_hh_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_3, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(Results_hh_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_4, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(Results_hh_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_5, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(Results_hh_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_6, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "    \n",
    "    ROC_Results = open('/data/github/result/MPNN_ROC'+str(epoch), 'w')\n",
    "\n",
    "    test_sig = 0.0\n",
    "    test_Nsig, test_Nbkg = 0, 0\n",
    "    for temp_cut in np.linspace(0.9, 1.0, 10000):\n",
    "        pre = (test_out[:, 1]-temp_cut>=0).reshape(-1, 6).astype(int)\n",
    "        tru = test_y[:]\n",
    "        dev = pre-tru\n",
    "        dev = abs(np.sum(dev, 1))<5\n",
    "        \n",
    "        hh = sum(dev[:5000])\n",
    "        tt = sum(1 - dev[5000: 5000 + 19000])\n",
    "        tw = sum(1 - dev[5000 + 19000: 5000 + 19000 + 800])\n",
    "        tth = sum(1 - dev[5000 + 19000 + 800: 5000 + 19000 + 800 + 100])\n",
    "        ttv = sum(1 - dev[5000 + 19000 + 800 + 100: 5000 + 19000 + 800 + 100 + 100])\n",
    "        llbj = sum(1 - dev[5000 + 19000 + 800 + 100 + 100: 5000 + 19000 + 800 + 100 + 100 + 240])\n",
    "        tatabb = sum(1 - dev[5000 + 19000 + 800 + 100 + 100 + 240: 5000 + 19000 + 800 + 100 + 100 + 240 + 10])\n",
    "\n",
    "        Nsig = round( float( 3000*0.0214964*hh/5000*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg = round( float( 3000*(120.907*1.596*tt/19000 + 4.38354*tw/800 + 0.15258*1.27*tth/100 + 0.157968*1.54*ttv/100 + 1.22936*llbj/240 + 0.011392*tatabb/10)*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tt = round( float( 3000*120.907*1.596*tt/19000*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tw = round( float( 3000*4.38354*tw/800*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tth = round( float( 3000*0.15258*1.27*tth/100*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_ttv = round( float( 3000*0.157968*1.54*ttv/100*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_llbj = round( float( 3000*1.22936*llbj/240*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tatabb = round( float( 3000*0.011392*tatabb/10*(0.8**2)/(0.7**2) ), 3)\n",
    "        SobSqrtB = round( float( IndiLikeRatioDis(float( Nsig ),float( Nbkg ) )  ) ,   3 )\n",
    "        ROC_Results.write(str(Nsig) + ' ' + str(Nbkg) + ' ' + str(SobSqrtB) + ' ' + str(Nbkg_tt) + ' ' + str(Nbkg_tw) + ' ' + str(Nbkg_tth) + ' ' + str(Nbkg_ttv) + ' ' + str(Nbkg_llbj) + ' ' + str(Nbkg_tatabb)   ) \n",
    "        ROC_Results.write('\\n')\n",
    "\n",
    "    ROC_Results.close()    \n",
    "\n",
    "    ROC_Results= np.loadtxt('/data/github/result/MPNN_ROC'+str(epoch))\n",
    "\n",
    "    SB=[]\n",
    "    hh=[]\n",
    "    tt=[]\n",
    "    tw=[]\n",
    "    tth=[]\n",
    "    ttv=[]\n",
    "    llbj=[]\n",
    "    tatabb=[]\n",
    "\n",
    "    for n in range(len(ROC_Results)):  \n",
    "        SB.append(ROC_Results[n][2])\n",
    "        hh.append(ROC_Results[n][0])\n",
    "        tt.append(ROC_Results[n][3])\n",
    "        tw.append(ROC_Results[n][4])\n",
    "        tth.append(ROC_Results[n][5])\n",
    "        ttv.append(ROC_Results[n][6])\n",
    "        llbj.append(ROC_Results[n][7])\n",
    "        tatabb.append(ROC_Results[n][8])\n",
    "\n",
    "    plt.plot(hh,SB, color='r', label='Significance')\n",
    "    plt.xlabel(r'$ N_s $', fontsize=20)\n",
    "    plt.ylabel(r'Significance', fontsize=20)\n",
    "    plt.legend(loc='best', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    j=SB.index(max(SB))\n",
    "\n",
    "    print('\\nsignificance: {:.3f} hh: {:.3f} tt: {:.3f} tw: {:.3f} tth: {:.3f} ttv: {:.3f} llbj: {:.3f} tatabb: {:.3f} \\n'.format(SB[j], hh[j], tt[j], tw[j], tth[j], ttv[j], llbj[j], tatabb[j]))\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        sig = max(SB)\n",
    "        best_sig = max(best_sig,sig)           \n",
    "\n",
    "    end=time.time()\n",
    "\n",
    "    print('* Best Significance : {:.3f} *'.format(best_sig))\n",
    "\n",
    "    print('Epoch time: {:.2f} mins'.format((end-start)/60))\n",
    "    print('='*69)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "jun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
