{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbef8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import sys\n",
    "import cmath\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b79fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetTrainData(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.x = torch.from_numpy( np.load('/data/github/data/diHiggs_neutrino_train_data.npy').astype(np.float32) )\n",
    "        #                                               hh               tt             tw             tth            ttv            llbj           tatabb\n",
    "        self.y = torch.from_numpy( np.concatenate((np.ones(19000), np.zeros(9900), np.zeros(5500), np.zeros(200), np.zeros(250), np.zeros(1000), np.zeros(60))).astype(np.int) )\n",
    "        self.n_samples = 35910\n",
    "                \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    \n",
    "class JetTestData(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.x = torch.from_numpy( np.load('/data/github/data/diHiggs_neutrino_test_data.npy').astype(np.float32) )\n",
    "        #                                               hh              tt              tw            tth            ttv            llbj          tatabb\n",
    "        self.y = torch.from_numpy( np.concatenate((np.ones(5000), np.zeros(19000), np.zeros(800), np.zeros(100), np.zeros(100), np.zeros(240), np.zeros(10))).astype(np.int) )\n",
    "        self.n_samples = 25250\n",
    "                \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1dad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_data = JetTrainData()\n",
    "test_data = JetTestData()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, int(batch_size/2), idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(images[idx,2], cmap='gray')\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50eb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=256):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(1, 256, \n",
    "                              kernel_size=(5,3,3), stride=1, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(256, 256, \n",
    "                              kernel_size=(3,3), stride=1, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(256, 256, \n",
    "                              kernel_size=(3,3), stride=1, padding=0)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 256, \n",
    "                              kernel_size=(3,3), stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x.unsqueeze(1))\n",
    "        x=(F.relu(x)).squeeze(2)\n",
    "        x=self.conv2(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.conv3(x)\n",
    "        x=F.relu(x)  \n",
    "        x=self.conv4(x)\n",
    "        x=F.relu(x) \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                      kernel_size=3, stride=1, padding=0)\n",
    "            for _ in range(num_capsules)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        u = [capsule(x).view(batch_size,  32* 40 * 40, 1) for capsule in self.capsules]\n",
    "        u = torch.cat(u, dim=-1)\n",
    "        u_squash = self.squash(u)\n",
    "        \n",
    "        return u_squash\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \n",
    "        \n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "def dynamic_routing(b_ij, u_hat, squash, routing_iterations=3):\n",
    "    for iteration in range(routing_iterations):\n",
    "        c_ij = helpers.softmax(b_ij, dim=2)\n",
    "        \n",
    "        s_j = (c_ij * u_hat).sum(dim=2, keepdim=True)\n",
    "        \n",
    "        v_j = squash(s_j)\n",
    "\n",
    "        if iteration < routing_iterations - 1:\n",
    "            a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\n",
    "            \n",
    "            b_ij = b_ij + a_ij\n",
    "    \n",
    "    return v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ON_GPU = torch.cuda.is_available()\n",
    "\n",
    "if(TRAIN_ON_GPU):\n",
    "    print('Training on GPU!')\n",
    "else:\n",
    "    print('Only CPU available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=2, previous_layer_nodes=32*40*40, \n",
    "                 in_channels=8, out_channels=16):\n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.num_capsules = num_capsules\n",
    "        self.previous_layer_nodes = previous_layer_nodes \n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(num_capsules, previous_layer_nodes, \n",
    "                                          in_channels, out_channels))\n",
    "\n",
    "    def forward(self, u):\n",
    "        u = u[None, :, :, None, :]\n",
    "        W = self.W[:, None, :, :, :]\n",
    "        \n",
    "        u_hat = torch.matmul(u, W)\n",
    "        \n",
    "        b_ij = torch.zeros(*u_hat.size())\n",
    "\n",
    "        if TRAIN_ON_GPU:\n",
    "            b_ij = b_ij.cuda()\n",
    "\n",
    "        v_j = dynamic_routing(b_ij, u_hat, self.squash, routing_iterations=3)\n",
    "\n",
    "        return v_j\n",
    "    \n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)    \n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_vector_length=16, input_capsules=2, hidden_dim=512):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        input_dim = input_vector_length * input_capsules\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim*2, 5*50*50),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "        classes = F.softmax(classes, dim=-1)\n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        \n",
    "        sparse_matrix = torch.eye(2)\n",
    "        if TRAIN_ON_GPU:\n",
    "            sparse_matrix = sparse_matrix.cuda()\n",
    "\n",
    "        y = sparse_matrix.index_select(dim=0, index=max_length_indices.data)\n",
    "        \n",
    "        x = x * y[:, :, None]\n",
    "        \n",
    "        flattened_x = x.contiguous().view(x.size(0), -1)\n",
    "        \n",
    "        reconstructions = self.linear_layers(flattened_x)\n",
    "\n",
    "        return reconstructions, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b597245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CapsuleNetwork, self).__init__()\n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_capsules = PrimaryCaps()\n",
    "        self.digit_capsules = DigitCaps()\n",
    "        self.decoder = Decoder()\n",
    "                \n",
    "    def forward(self, images):\n",
    "        primary_caps_output = self.primary_capsules(self.conv_layer(images))\n",
    "        caps_output = self.digit_capsules(primary_caps_output).squeeze().transpose(0,1)\n",
    "        reconstructions, y = self.decoder(caps_output)\n",
    "        \n",
    "        return caps_output, reconstructions, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_net = CapsuleNetwork()\n",
    "\n",
    "print(capsule_net)\n",
    "\n",
    "if TRAIN_ON_GPU:\n",
    "    capsule_net = capsule_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.reconstruction_loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, x, labels, images, reconstructions):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "\n",
    "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
    "        margin_loss = margin_loss.sum()\n",
    "\n",
    "        images = images.view(reconstructions.size()[0], -1)\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "\n",
    "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8776a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CapsuleLoss()\n",
    "optimizer = optim.Adam(capsule_net.parameters(), lr=1e-4, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(capsule_net, criterion, optimizer, epoch, print_every=300):\n",
    "    \n",
    "    class_correct = list(0. for i in range(2))\n",
    "    class_total = list(0. for i in range(2))\n",
    "\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    capsule_net.train()\n",
    "\n",
    "    for batch_i, (images, target) in enumerate(train_loader):\n",
    "\n",
    "        target = torch.eye(2).index_select(dim=0, index=target)\n",
    "\n",
    "        if TRAIN_ON_GPU:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        caps_output, reconstructions, y = capsule_net(images)\n",
    "        loss = criterion(caps_output, target, images, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        _, pred = torch.max(y.data.cpu(), 1)\n",
    "        _, target_shape = torch.max(target.data.cpu(), 1)\n",
    "\n",
    "        correct = np.squeeze(pred.eq(target_shape.data.view_as(pred)))\n",
    "        for i in range(len(target)):\n",
    "            label = target_shape.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "    loss = train_loss/len(train_loader)\n",
    "    accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "    \n",
    "    print(f'\\n Train Epoch: {epoch} \\tLoss: {loss:.6f}')\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(capsule_net, test_loader):\n",
    "\n",
    "    DNN_score = open('/data/github/result/CapsNet_DNN_score.TXT', 'a')    \n",
    "    \n",
    "    class_correct = list(0. for i in range(2))\n",
    "    class_total = list(0. for i in range(2))\n",
    "    \n",
    "    test_loss = 0\n",
    "\n",
    "    capsule_net.eval()\n",
    "    \n",
    "    for batch_i, (images, target) in enumerate(test_loader):\n",
    "        target = torch.eye(2).index_select(dim=0, index=target)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        if TRAIN_ON_GPU:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "\n",
    "        caps_output, reconstructions, y = capsule_net(images)\n",
    "        loss = criterion(caps_output, target, images, reconstructions)\n",
    "        test_loss += loss.item() \n",
    "        _, pred = torch.max(y.data.cpu(), 1)\n",
    "        _, target_shape = torch.max(target.data.cpu(), 1)\n",
    "\n",
    "        if batch_i < int(len(test_data)/batch_size):\n",
    "            for n in range(0,batch_size):\n",
    "                hh=math.sqrt((caps_output[n][1]**2).sum())\n",
    "                DNN_score.write(str(hh))\n",
    "                DNN_score.write('\\n')                   \n",
    "                       \n",
    "        if int(len(target)/batch_size) == batch_i:\n",
    "            for n in range (0,int((len(test_data)/batch_size-int(len(test_data)/batch_size))*batch_size)):\n",
    "                hh=math.sqrt((caps_output[n][1]**2).sum())\n",
    "                DNN_score.write(str(hh))\n",
    "                DNN_score.write('\\n')         \n",
    "\n",
    "        correct = np.squeeze(pred.eq(target_shape.data.view_as(pred)))\n",
    "        for i in range(len(target)):\n",
    "            label = target_shape.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    loss = test_loss/len(test_loader)\n",
    "    accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "    \n",
    "    print(f'\\nTest set: Loss: {loss:.6f}, Accuracy: {round(np.sum(class_correct))}/{round(np.sum(class_total))}({(100. * accuracy):.2f}%)\\n')\n",
    "    print('----------------------------------------------------')\n",
    "    \n",
    "    DNN_score.close()    \n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Like(s, b, u, n):\n",
    "    return math.e**((n*s+b)*math.log(u*s+b)-math.lgamma(n*s+b+1)-(u*s+b))\n",
    "\n",
    "def IndiLikeRatioDis(NS1, NB1):\n",
    "    return math.sqrt(-2*math.log((Like(NS1, NB1, 0.0, 1.0))/(Like(NS1, NB1, 1.0, 1.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff973a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DNN_score = open('/data/github/result/CapsNet_DNN_score.TXT', 'w')    \n",
    "\n",
    "Train_Loss = []\n",
    "Train_Accuracy = []\n",
    "Test_Loss = []\n",
    "Test_Accuracy = []\n",
    "\n",
    "epochs = 1\n",
    "best_sig = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start=time.time()\n",
    "    print('########### Training epoch {} start ###########'.format(epoch))\n",
    "    \n",
    "    train_loss, train_accuracy = train(capsule_net, criterion, optimizer, epoch)\n",
    "    test_loss, test_accuracy = test(capsule_net, test_loader)\n",
    "\n",
    "    Train_Loss.append(train_loss)\n",
    "    Train_Accuracy.append(train_accuracy)\n",
    "    Test_Loss.append(test_loss)\n",
    "    Test_Accuracy.append(test_accuracy)\n",
    "    \n",
    "    Results = np.loadtxt('/data/github/result/CapsNet_DNN_score.TXT')\n",
    "\n",
    "    epoch_ = epoch\n",
    "\n",
    "    Results_hh_1=Results[len(test_data)*(epoch_-1):len(test_data)*(epoch_-1)+5000]\n",
    "    Results_tt_1=Results[len(test_data)*(epoch_-1)+5000:len(test_data)*(epoch_-1)+5000+19000]\n",
    "    Results_tw_1=Results[len(test_data)*(epoch_-1)+5000+19000:len(test_data)*(epoch_-1)+5000+19000+800]\n",
    "    Results_tth_1=Results[len(test_data)*(epoch_-1)+5000+19000+800:len(test_data)*(epoch_-1)+5000+19000+800+100]\n",
    "    Results_ttv_1=Results[len(test_data)*(epoch_-1)+5000+19000+800+100:len(test_data)*(epoch_-1)+5000+19000+800+100+100]\n",
    "    Results_llbj_1=Results[len(test_data)*(epoch_-1)+5000+19000+800+100+100:len(test_data)*(epoch_-1)+5000+19000+800+100+100+240]\n",
    "    Results_tatabb_1=Results[len(test_data)*(epoch_-1)+5000+19000+800+100+100+240:len(test_data)*epoch_]\n",
    "\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='Time New Roman')\n",
    "\n",
    "    logs = False\n",
    "\n",
    "    axislabels = [ r'$DNN $']\n",
    "\n",
    "    Yaxislabels = [ r'$DNN $']\n",
    "\n",
    "    Bmax = 1\n",
    "    Bmin = 0\n",
    "    plt.xlim(0, 1)\n",
    "    bins = np.linspace(Bmin, Bmax,  25)\n",
    "    plt.hist(Results_hh_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "    \n",
    "    ROC_Results = open('/data/github/result/CapsNet_ROC.TXT'+str(epoch), 'w')\n",
    "    \n",
    "    XSig_box = []\n",
    "\n",
    "    Xbkg_box = []\n",
    "\n",
    "    Xbkg_tt_box = []\n",
    "\n",
    "    Xbkg_tw_box = []\n",
    "\n",
    "    Xbkg_tth_box = []\n",
    "\n",
    "    Xbkg_ttv_box = []\n",
    "\n",
    "    Xbkg_llbj_box = []\n",
    "\n",
    "    Xbkg_tatabb_box = []\n",
    "\n",
    "    nn = 10000\n",
    "\n",
    "    Ival = 0.9\n",
    "\n",
    "    Xreco_Sig = 0.0214964\n",
    "\n",
    "    Xreco_tt = 120.907 * 1.596\n",
    "\n",
    "    Xreco_tw = 4.38354\n",
    "\n",
    "    Xreco_tth = 0.15258 * 1.27\n",
    "\n",
    "    Xreco_ttv = 0.157968 * 1.54\n",
    "\n",
    "    Xreco_llbj = 1.22936\n",
    "\n",
    "    Xreco_tatabb = 0.011392\n",
    "\n",
    "    for j in range(0, nn):\n",
    "\n",
    "        roc_sig = 0\n",
    "        roc_bkg_tt = 0\n",
    "        roc_bkg_tw = 0\n",
    "        roc_bkg_tth = 0\n",
    "        roc_bkg_ttv = 0\n",
    "        roc_bkg_llbj = 0\n",
    "        roc_bkg_tatabb = 0\n",
    "\n",
    "        for i in range(0, len(Results_hh_1)):\n",
    "            if Results_hh_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_sig = roc_sig + 1\n",
    "            \n",
    "        for i in range(0, len(Results_tt_1 )):\n",
    "            if Results_tt_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_tt = roc_bkg_tt + 1\n",
    "            \n",
    "        for i in range(0, len(Results_tw_1) ):\n",
    "            if Results_tw_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_tw = roc_bkg_tw + 1\n",
    "\n",
    "        for i in range(0, len(Results_tth_1 )):\n",
    "            if Results_tth_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_tth = roc_bkg_tth + 1\n",
    "            \n",
    "        for i in range(0, len(Results_ttv_1) ):\n",
    "            if Results_ttv_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_ttv = roc_bkg_ttv + 1\n",
    "\n",
    "        for i in range(0, len(Results_llbj_1 )):\n",
    "            if Results_llbj_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_llbj = roc_bkg_llbj + 1\n",
    "            \n",
    "        for i in range(0, len(Results_tatabb_1) ):\n",
    "            if Results_tatabb_1[i] > float( Ival + float(0.1*j)/float(nn) ) :\n",
    "                roc_bkg_tatabb = roc_bkg_tatabb + 1\n",
    "            \n",
    "        XSig_box.append( float( float(Xreco_Sig)*float( roc_sig ) / float( len(Results_hh_1) ) )   )\n",
    "\n",
    "        Xbkg_box.append( float( float(Xreco_tt)*float( roc_bkg_tt ) / float( len(Results_tt_1) ) ) + float( float(Xreco_tw)*float( roc_bkg_tw ) / float( len(Results_tw_1) ) ) + float( float(Xreco_tth)*float( roc_bkg_tth ) / float( len(Results_tth_1) ) ) + float( float(Xreco_ttv)*float( roc_bkg_ttv ) / float( len(Results_ttv_1) ) ) + float( float(Xreco_llbj)*float( roc_bkg_llbj ) / float( len(Results_llbj_1) ) ) + float( float(Xreco_tatabb)*float( roc_bkg_tatabb ) / float( len(Results_tatabb_1) ) )   )\n",
    "\n",
    "        Xbkg_tt_box.append( float( float(Xreco_tt)*float( roc_bkg_tt ) / float( len(Results_tt_1) ) )  )\n",
    "\n",
    "        Xbkg_tw_box.append( float( float(Xreco_tw)*float( roc_bkg_tw ) / float( len(Results_tw_1) ) )   )\n",
    "\n",
    "        Xbkg_tth_box.append( float( float(Xreco_tth)*float( roc_bkg_tth ) / float( len(Results_tth_1) ) )  )\n",
    "\n",
    "        Xbkg_ttv_box.append( float( float(Xreco_ttv)*float( roc_bkg_ttv ) / float( len(Results_ttv_1) ) )   )\n",
    "\n",
    "        Xbkg_llbj_box.append( float( float(Xreco_llbj)*float( roc_bkg_llbj ) / float( len(Results_llbj_1) ) )  )\n",
    "\n",
    "        Xbkg_tatabb_box.append( float( float(Xreco_tatabb)*float( roc_bkg_tatabb ) / float( len(Results_tatabb_1) ) )   )    \n",
    "\n",
    "    for j in range(0, len(XSig_box) ):\n",
    "\n",
    "        if float( Xbkg_box[j] ) == 0 :\n",
    "            break\n",
    "\n",
    "        Nsig = round( float( 3000*XSig_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "\n",
    "        Nbkg = round( float( 3000*Xbkg_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_tt = round( float( 3000*Xbkg_tt_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_tw = round( float( 3000*Xbkg_tw_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_tth = round( float( 3000*Xbkg_tth_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_ttv = round( float( 3000*Xbkg_ttv_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_llbj = round( float( 3000*Xbkg_llbj_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "    \n",
    "        Nbkg_tatabb = round( float( 3000*Xbkg_tatabb_box[j]*(0.8**2/0.7**2) ), 3)\n",
    "\n",
    "        SobSqrtB = round( float( IndiLikeRatioDis(float( Nsig ),float( Nbkg ) )  ) ,   3 )\n",
    "        ROC_Results.write(str(Nsig) + ' ' + str(Nbkg) + ' ' + str(SobSqrtB) + ' ' + str(Nbkg_tt) + ' ' + str(Nbkg_tw) + ' ' + str(Nbkg_tth) + ' ' + str(Nbkg_ttv) + ' ' + str(Nbkg_llbj) + ' ' + str(Nbkg_tatabb)   ) \n",
    "        ROC_Results.write('\\n')\n",
    "\n",
    "    ROC_Results.close()\n",
    "    \n",
    "    ROC_Results= np.loadtxt('/data/github/result/CapsNet_ROC.TXT'+str(epoch))\n",
    "    \n",
    "    SB=[]\n",
    "    hh=[]\n",
    "    tt=[]\n",
    "    tw=[]\n",
    "    tth=[]\n",
    "    ttv=[]\n",
    "    llbj=[]\n",
    "    tatabb=[]\n",
    "\n",
    "    for n in range(len(ROC_Results)):  \n",
    "        SB.append(ROC_Results[n][2])\n",
    "        hh.append(ROC_Results[n][0])\n",
    "        tt.append(ROC_Results[n][3])\n",
    "        tw.append(ROC_Results[n][4])\n",
    "        tth.append(ROC_Results[n][5])\n",
    "        ttv.append(ROC_Results[n][6])\n",
    "        llbj.append(ROC_Results[n][7])\n",
    "        tatabb.append(ROC_Results[n][8])\n",
    "        \n",
    "    plt.plot(hh,SB, color='r', label='Significance')\n",
    "    plt.xlabel(r'$ N_s $', fontsize=20)\n",
    "    plt.ylabel(r'Significance', fontsize=20)\n",
    "    plt.legend(loc='best', fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    j=SB.index(max(SB))\n",
    "    print('\\nsignificance: {:.3f} hh: {:.3f} tt: {:.3f} tw: {:.3f} tth: {:.3f} ttv: {:.3f} llbj: {:.3f} tatabb: {:.3f} \\n'.format(SB[j], hh[j], tt[j], tw[j], tth[j], ttv[j], llbj[j], tatabb[j]))         \n",
    " \n",
    "    if epoch % 1 == 0:\n",
    "        sig = max(SB)\n",
    "        best_sig = max(best_sig,sig)           \n",
    "        \n",
    "    end=time.time()\n",
    "    \n",
    "    print('* Best Significance : {:.3f} *'.format(best_sig))\n",
    "\n",
    "    print('Epoch time: {:.2f} mins'.format((end-start)/60))\n",
    "    print('='*69)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "jun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
