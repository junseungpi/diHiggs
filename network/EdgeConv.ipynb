{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, OptPairTensor, Adj, Size\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "\n",
    "from ROOT import TLorentzVector\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.tutorials.cnn_utils import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy( np.load('/data/github/data/diHiggs_kin_train_data.npy').astype(np.float32))\n",
    "data2 = torch.from_numpy( np.load('/data/github/data/diHiggs_kin_test_data.npy').astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_, e2_ = [], []\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if(i!=j):\n",
    "            e1_.append(i)\n",
    "            e2_.append(j)\n",
    "\n",
    "\n",
    "def graph_trans(d, y=1, e1=e1_, e2=e2_):\n",
    "    d = d/100.\n",
    "    b1 = d[17], d[18], d[19], d[20]\n",
    "    b2 = d[21], d[22], d[23], d[24]\n",
    "    l1 = d[25], d[26], d[27], d[28]\n",
    "    l2 = d[29], d[30], d[31], d[32]\n",
    "    nu1 = d[33], d[34], d[35], d[36]\n",
    "    nu2 = d[37], d[38], d[39], d[40]\n",
    "\n",
    "\n",
    "    x = torch.tensor([b1, b2, l1, l2, nu1, nu2], dtype=torch.float)\n",
    "\n",
    "    GNN_index = torch.tensor([e1, e2], dtype=torch.long)\n",
    "\n",
    "\n",
    "    graph = Data(x=x, y=[y, y, y, y, y, y], GNN_index=GNN_index)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_list = []\n",
    "for idx, d in enumerate(data):\n",
    "    if(idx<=19000):\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "    train_graph_list.append(graph_trans(d, y))\n",
    "\n",
    "test_graph_list = []\n",
    "for idx, d in enumerate(data2):\n",
    "    if(idx<=5000):\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "    test_graph_list.append(graph_trans(d, y))\n",
    "    \n",
    "train_loader = DataLoader(train_graph_list, \n",
    "                          batch_size=130,\n",
    "                          shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_graph_list, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, hidden, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.mlp1 = Seq(Linear(4*in_channels, hidden, bias=True),\n",
    "                       nn.LeakyReLU())\n",
    "        self.mlp2 = Seq(Linear(hidden+in_channels, out_channels, bias=True),\n",
    "                       nn.LeakyReLU())\n",
    "\n",
    "\n",
    "    def forward(self, x, GNN_index):\n",
    "        out = self.propagate(GNN_index, x=x)\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        out = self.mlp2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        x_j = torch.cat([x_i, x_i*x_j, x_i+x_j, x_j-x_i], dim=1)\n",
    "        x_j = self.mlp1(x_j)\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73803a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp0 = Seq(Linear(4, 54, bias=True),\n",
    "                               nn.LeakyReLU())\n",
    "        self.conv1 = GNNConv(54, 231, 221)\n",
    "        self.conv2 = GNNConv(221, 229, 164)\n",
    "        self.conv3 = GNNConv(164, 131, 215)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        self.mlp1 = Seq(Linear(215*6, 54, bias=True),\n",
    "                        nn.LeakyReLU(),\n",
    "                        Linear(54, 2, bias=True),\n",
    "                        nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, GNN_index = data.x, data.GNN_index\n",
    "\n",
    "        x = self.mlp0(x)\n",
    "        x = self.conv1(x, GNN_index)\n",
    "        x = self.conv2(x, GNN_index)\n",
    "        x = self.conv3(x, GNN_index)\n",
    "        x = x.reshape(-1, x.shape[1]*6)\n",
    "        x = self.mlp1(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69100504",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EdgeConv().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=9.203442233965491e-07,\n",
    "                             betas=(0.9294469864692979, 0.9909760356430601),\n",
    "                             weight_decay=0.03206031460677253,\n",
    "                            )\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    loss_val = []\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        label = [1 if i==[1, 1, 1, 1, 1, 1] else 0 for i in batch.y]\n",
    "        label = torch.tensor(label).to(device)\n",
    "        out = model(batch.to(device))\n",
    "    \n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val.append(loss.item())\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    loss = np.mean(loss_val)\n",
    "    \n",
    "    print(f'\\n Train Epoch: {epoch} \\tLoss: {loss:.6f}')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    DNN_score = open('/data/github/result/EdgeConv_DNN_score.TXT', 'a')    \n",
    "\n",
    "    model.eval()\n",
    "    loss_val = []\n",
    "    for idx, batch in enumerate(test_loader):\n",
    "        out = model(batch.to(device)) \n",
    "        label = [1 if i==[1, 1, 1, 1, 1, 1] else 0 for i in batch.y]\n",
    "        label = torch.tensor(label).to(device)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        loss_val.append(loss.item())\n",
    "\n",
    "        out = (out.cpu().detach().numpy())[:]\n",
    "        if(idx==0):\n",
    "            test_out = out[:]\n",
    "            test_y = np.array(batch.y)[:]\n",
    "        else:\n",
    "            test_out = np.concatenate((test_out[:], out[:]), axis=0)\n",
    "            test_y = np.concatenate((test_y[:], np.array(batch.y)[:]), axis=0)\n",
    "    \n",
    "    for n in range(0,len(test_out)):\n",
    "        DNN_score.write(str((test_out[:,0:1][n].item())) + ' ' + str((test_out[:,1:2][n].item())) + ' ' + str((test_y[:,0:1][n].item())) + ' ' + str((test_y[:,1:2][n].item())) + ' ' + str((test_y[:,2:3][n].item())) + ' ' + str((test_y[:,3:4][n].item())) + ' ' + str((test_y[:,4:5][n].item())) + ' ' + str((test_y[:,5:6][n].item())))\n",
    "        DNN_score.write('\\n')\n",
    "\n",
    "    loss = np.mean(loss_val)\n",
    "\n",
    "    print(f'\\nTest set: Loss: {loss:.6f}\\n')\n",
    "    print('----------------------------------------------------')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a500e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Like(s, b, u, n):\n",
    "    return math.e**((n*s+b)*math.log(u*s+b)-math.lgamma(n*s+b+1)-(u*s+b))\n",
    "\n",
    "def IndiLikeRatioDis(NS1, NB1):\n",
    "    return math.sqrt(-2*math.log((Like(NS1, NB1, 0.0, 1.0))/(Like(NS1, NB1, 1.0, 1.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_score = open('/data/github/result/EdgeConv_DNN_score.TXT', 'w')    \n",
    "\n",
    "Train_Loss = []\n",
    "Test_Loss = []\n",
    "\n",
    "epochs = 1\n",
    "best_sig = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start=time.time()\n",
    "    print('########### Training epoch {} start ###########'.format(epoch))\n",
    "    \n",
    "    train_loss = train(model, train_loader)\n",
    "    test_loss = test(model, test_loader)\n",
    "\n",
    "    Train_Loss.append(train_loss)\n",
    "    Test_Loss.append(test_loss)\n",
    "    \n",
    "    epoch_ = epoch\n",
    "\n",
    "    Results = np.loadtxt('/data/github/result/EdgeConv_DNN_score.TXT')\n",
    "\n",
    "    Results = Results[25250*(epoch_-1):25250*(epoch_)]\n",
    "\n",
    "    test_out = Results[:,:2]\n",
    "    test_y = Results[:,2:]\n",
    "    \n",
    "    Results_hh_1=test_out[:,1:2][:5000]\n",
    "    Results_tt_1=test_out[:,1:2][5000:5000+19000]\n",
    "    Results_tw_1=test_out[:,1:2][5000+19000:5000+19000+800]\n",
    "    Results_tth_1=test_out[:,1:2][5000+19000+800:5000+19000+800+100]\n",
    "    Results_ttv_1=test_out[:,1:2][5000+19000+800+100:5000+19000+800+100+100]\n",
    "    Results_llbj_1=test_out[:,1:2][5000+19000+800+100+100:5000+19000+800+100+100+240]\n",
    "    Results_tatabb_1=test_out[:,1:2][5000+19000+800+100+100+240:5000+19000+800+100+100+240+10]\n",
    "\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='Time New Roman')\n",
    "\n",
    "    logs = False\n",
    "\n",
    "    axislabels = [ r'$DNN $']\n",
    "\n",
    "    Yaxislabels = [ r'$DNN $']\n",
    "\n",
    "    Bmax = 1\n",
    "    Bmin = 0\n",
    "    plt.xlim(0, 1)\n",
    "    bins = np.linspace(Bmin, Bmax,  25)\n",
    "    plt.hist(Results_hh_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='black', label= r'$h \\; h$')\n",
    "    plt.hist(Results_tt_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='blue', label= r'$t \\; \\overline{t}$')\n",
    "    plt.hist(Results_tw_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, color='red', label= r'$t \\; w$')\n",
    "    plt.hist(Results_tth_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; h$')\n",
    "    plt.hist(Results_ttv_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$t \\; \\overline{t} \\; v$')\n",
    "    plt.hist(Results_llbj_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$l \\; l \\; b \\; j$')\n",
    "    plt.hist(Results_tatabb_1, bins = bins, alpha=1, density=True, histtype='step', align = 'mid', linewidth = 1.5, log=logs, label= r'$\\tau \\; \\tau \\; b \\; b$')\n",
    "    plt.legend(loc=9,fontsize = 10)\n",
    "    plt.xlabel(axislabels[0], fontsize = 20)\n",
    "    plt.ylabel(r'$\\rm{(1/\\sigma) \\; d \\sigma / d }$' + Yaxislabels[0]    , fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "    ROC_Results = open('/data/github/result/EdgeConv_ROC'+str(epoch), 'w')\n",
    "\n",
    "    test_sig = 0.0\n",
    "    test_Nsig, test_Nbkg = 0, 0\n",
    "    for temp_cut in np.linspace(0.9, 1.0, 10000):\n",
    "        pre = (test_out[:, 1]-temp_cut>=0).astype(int)\n",
    "\n",
    "        hh = sum(pre[:5000])\n",
    "        tt = sum(pre[5000: 5000 + 19000])\n",
    "        tw = sum(pre[5000 + 19000: 5000 + 19000 + 800])\n",
    "        tth = sum(pre[5000 + 19000 + 800: 5000 + 19000 + 800 + 100])\n",
    "        ttv = sum(pre[5000 + 19000 + 800 + 100: 5000 + 19000 + 800 + 100 + 100])\n",
    "        llbj = sum(pre[5000 + 19000 + 800 + 100 + 100: 5000 + 19000 + 800 + 100 + 100 + 240])\n",
    "        tatabb = sum(pre[5000 + 19000 + 800 + 100 + 100 + 240: 5000 + 19000 + 800 + 100 + 100 + 240 + 10])\n",
    "\n",
    "        Nsig = round( float( 3000*0.0214964*hh/5000*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg = round( float( 3000*(120.907*1.596*tt/19000 + 4.38354*tw/800 + 0.15258*1.27*tth/100 + 0.157968*1.54*ttv/100 + 1.22936*llbj/240 + 0.011392*tatabb/10)*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tt = round( float( 3000*120.907*1.596*tt/19000*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tw = round( float( 3000*4.38354*tw/800*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tth = round( float( 3000*0.15258*1.27*tth/100*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_ttv = round( float( 3000*0.157968*1.54*ttv/100*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_llbj = round( float( 3000*1.22936*llbj/240*(0.8**2)/(0.7**2) ), 3)\n",
    "        Nbkg_tatabb = round( float( 3000*0.011392*tatabb/10*(0.8**2)/(0.7**2) ), 3)\n",
    "        SobSqrtB = round( float( IndiLikeRatioDis(float( Nsig ),float( Nbkg ) )  ) ,   3 )\n",
    "        ROC_Results.write(str(Nsig) + ' ' + str(Nbkg) + ' ' + str(SobSqrtB) + ' ' + str(Nbkg_tt) + ' ' + str(Nbkg_tw) + ' ' + str(Nbkg_tth) + ' ' + str(Nbkg_ttv) + ' ' + str(Nbkg_llbj) + ' ' + str(Nbkg_tatabb)   ) \n",
    "        ROC_Results.write('\\n')\n",
    "\n",
    "    ROC_Results.close()    \n",
    "\n",
    "    ROC_Results= np.loadtxt('/data/github/result/EdgeConv_ROC'+str(epoch))\n",
    "\n",
    "    SB=[]\n",
    "    hh=[]\n",
    "    tt=[]\n",
    "    tw=[]\n",
    "    tth=[]\n",
    "    ttv=[]\n",
    "    llbj=[]\n",
    "    tatabb=[]\n",
    "\n",
    "    for n in range(len(ROC_Results)):  \n",
    "        SB.append(ROC_Results[n][2])\n",
    "        hh.append(ROC_Results[n][0])\n",
    "        tt.append(ROC_Results[n][3])\n",
    "        tw.append(ROC_Results[n][4])\n",
    "        tth.append(ROC_Results[n][5])\n",
    "        ttv.append(ROC_Results[n][6])\n",
    "        llbj.append(ROC_Results[n][7])\n",
    "        tatabb.append(ROC_Results[n][8])\n",
    "\n",
    "    plt.plot(hh,SB, color='r', label='Significance')\n",
    "    plt.xlabel(r'$ N_s $', fontsize=20)\n",
    "    plt.ylabel(r'Significance', fontsize=20)\n",
    "    plt.legend(loc='best', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    j=SB.index(max(SB))\n",
    "\n",
    "    print('\\nsignificance: {:.3f} hh: {:.3f} tt: {:.3f} tw: {:.3f} tth: {:.3f} ttv: {:.3f} llbj: {:.3f} tatabb: {:.3f} \\n'.format(SB[j], hh[j], tt[j], tw[j], tth[j], ttv[j], llbj[j], tatabb[j]))\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        sig = max(SB)\n",
    "        best_sig = max(best_sig,sig)           \n",
    "\n",
    "    end=time.time()\n",
    "\n",
    "    print('* Best Significance : {:.3f} *'.format(best_sig))\n",
    "\n",
    "    print('Epoch time: {:.2f} mins'.format((end-start)/60))\n",
    "    print('='*69)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "jun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
